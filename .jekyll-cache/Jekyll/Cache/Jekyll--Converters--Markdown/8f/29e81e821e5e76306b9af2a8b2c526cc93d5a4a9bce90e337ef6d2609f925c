I"j<h2 id="如何讓爬蟲程式不被ban"><strong>如何讓爬蟲程式不被ban?</strong></h2>
<ol>
  <li>動態設置user agent</li>
  <li>使用代理IP</li>
</ol>

<p><a href="http://willdrevo.com/using-a-proxy-with-a-randomized-user-agent-in-python-requests" target="_blank">參考</a><br />
這裡主要介紹如何使用IP代理。</p>

<h2 id="proxy代理類型"><strong>proxy代理類型</strong></h2>
<p><a href="http://gohom.win/2016/01/20/proxy-type/" target="_blank">參考</a></p>
<ol>
  <li>
    <p>透明代理(Transparent Proxy)<br />
REMOTE_ADDR = Proxy IP<br />
HTTP_VIA = Proxy IP<br />
HTTP_X_FORWARDED_FOR = Your IP</p>
  </li>
  <li>
    <p>匿名代理(Anonymous Proxy)<br />
REMOTE_ADDR = proxy IP<br />
HTTP_VIA = proxy IP<br />
HTTP_X_FORWARDED_FOR = proxy IP</p>
  </li>
  <li>
    <p>混淆代理(Distorting Proxies)<br />
REMOTE_ADDR = Proxy IP<br />
HTTP_VIA = Proxy IP<br />
HTTP_X_FORWARDED_FOR = Random IP address</p>
  </li>
  <li>
    <p>高匿代理(Elite proxy或High Anonymity Proxy)<br />
REMOTE_ADDR = Proxy IP<br />
HTTP_VIA = not determined<br />
HTTP_X_FORWARDED_FOR = not determined<br /></p>
  </li>
</ol>

<h2 id="代理proxy哪裡找"><strong>代理proxy哪裡找？</strong></h2>
<p>這裡提供兩個我覺得品質比較好的proxy代理<br /></p>
<ol>
  <li>http://www.goubanjia.com/free/index.shtml<br /></li>
  <li>http://www.proxyserverlist24.top/<br /></li>
</ol>

<p><a href="https://github.com/shihs/proxy/blob/master/get_proxies.py" target="_blank">程式碼</a></p>

<h2 id="如何確定真的使用代理ip了"><strong>如何確定真的使用代理IP了？</strong></h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">requests</span>

<span class="c1"># 隨便google可以找到可以查詢自己IP的網站
</span>
<span class="n">url</span> <span class="o">=</span> <span class="s">"http://icanhazip.com/"</span>  <span class="c1"># 這個網站可以知道目前瀏覽的IP
</span><span class="n">proxies</span> <span class="o">=</span> <span class="p">{</span>
	<span class="s">"http"</span><span class="p">:</span><span class="s">"http://xx.xx.xxx:xxxx"</span><span class="p">,</span>
	<span class="s">"https"</span><span class="p">:</span><span class="s">"https://xx.xx.xxx:xxxx"</span><span class="p">,</span>

<span class="p">}</span>
<span class="c1">###注意
#要爬取的網站是使用什麼協定？http？https？
#網址可能會有轉址的情況，最後轉的那個網址才是真正的協定喔
</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">proxies</span> <span class="o">=</span> <span class="n">proxies</span><span class="p">)</span>
<span class="k">print</span> <span class="n">res</span><span class="p">.</span><span class="n">text</span>  <span class="c1"># 如果這個網站print出來的和proxies一樣，那就表示成功了
</span>

</code></pre></div></div>

<p>抓完proxy後，我將所有proxy儲存在csv檔案中，
要爬取網站的時候，先讀取該檔案，
只要被擋，就random使用proxy替換proxies。</p>

<p>如果所有proxy都用完再重新爬取，
網站上的proxy都會不停更換，
所以只要更新proxy庫就好。</p>

:ET