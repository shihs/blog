I"Ë<p><strong>MCMC æ˜¯ä»€éº¼ï¼Ÿ</strong></p>

<p>Markov Chain Monte Carlo ï¼ˆMCMCï¼‰æ˜¯ä¸€ç¨®æŠ½æ¨£æ–¹æ³•ï¼Œç”¨ä¾†è§£æ±ºç„¡æ³•ç›´æ¥æŠ½æ¨£çš„åˆ†ä½ˆçš„éš¨æ©ŸæŠ½æ¨£å•é¡Œã€‚</p>

<p><strong>The Goal of MCMC</strong></p>

<p>We want to sample from some distribution p, or approximate an \(E[f(x)] ~ where ~ (X \sim p)\)
<br />
é€šå¸¸ p æ˜¯ä¸€å€‹å¾ˆè¤‡é›œçš„ distributionï¼Œè¦å¾é€™å€‹åˆ†ä½ˆå– sample æ ¹æœ¬ä¸å¯èƒ½ï¼Œæ‰€ä»¥é€™æ™‚å€™å°±æœƒéœ€è¦ MCMCã€‚</p>

<hr />

<p><strong>ç‚ºä»€éº¼è¦ä½¿ç”¨ MCMCï¼Ÿ</strong></p>

<p>åœ¨ Baysian Inference ä¸­å¸¸ä½¿ç”¨åˆ°é€™å€‹å…¬å¼</p>

\[p(\theta\mid y) = \frac{p(y \mid \theta) p(\theta)}{\int p(y \mid \theta) p(\theta)d\theta}\]

<p>æˆ–æ˜¯ï¼Œå®ƒçš„åƒæ•¸ \(\theta\) çš„è²å¼ä¼°è¨ˆ</p>

\[\hat \theta = E[\theta \mid y] = \int \theta p(y \mid \theta) d \theta = \frac{\int \theta p(y \mid \theta) p(\theta)}{\int p(y \mid \theta) p(\theta)d\theta}\]

<p>å…¶ä¸­çš„ \(p(\theta)\) ç‚ºå…ˆé©—æ©Ÿç‡ (prior probability)ï¼ŒåŸºæœ¬ä¸Šæˆ‘å€‘ç„¡æ³•ç²å¾— \(p(\theta)\) çš„å€¼ï¼Œé€™æ™‚å€™å°±éœ€è¦ MCMCã€‚</p>

<hr />

<p>MCMC ç”±å…©éƒ¨åˆ†çš„è§€å¿µ (æ­¥é©Ÿ) çµ„æˆ, ä¸€å€‹æ˜¯ ã€ŒMarkov Chainã€ ï¼Œå¦ä¸€å€‹å‰‡æ˜¯ã€ŒMonte Carlo integrationã€ï¼Œæ¥ä¸‹ä¾†å°‡èªªæ˜é€™å…©å€‹éƒ¨åˆ†ã€‚</p>

<hr />

<p><strong>Monte Carlo Integration</strong></p>

<p>Monte Carlo Integration å¯ä»¥ä»¥æŠ½æ¨£å¹³å‡çš„æ–¹å¼è¨ˆç®—ä¸Šé¢çš„æœŸæœ›å€¼å¼å­</p>

\[E[\theta \mid y] \approx \frac{1}{n}\sum_{i=1}^{t}{(\theta_i \mid y)}, ~ \theta_i \stackrel{iid}{\sim} p(\theta \mid y)\]

<p>ä¹Ÿå°±æ˜¯èªªï¼Œä½¿ç”¨æ¨£æœ¬å¹³å‡æ•¸ä¾†ä¼°è¨ˆæœŸæœ›å€¼ã€‚é€™ä»¶äº‹æƒ…å¯ä»¥æˆç«‹æ˜¯å› ç‚ºï¼Œæ ¹æ“šå¤§æ•¸æ³•å‰‡ï¼Œç•¶æ¨£æœ¬æ•¸ n å¤ å¤§æ™‚ï¼Œæ¨£æœ¬çš„å¹³å‡æ•¸å°‡è¶¨è¿‘æ–¼æ¯é«”å¹³å‡æ•¸ã€‚</p>

<p>é€™æ¨£çœ‹èµ·ä¾† Monte Carlo Integration è®“æˆ‘å€‘çœå»äº†ä¸Šé¢é‚£å€‹çœ‹èµ·ä¾†è¤‡é›œçš„ç©åˆ†å¼å­ã€‚ä½†æ˜¯ï¼Œç¾å¯¦ç”Ÿæ´»ä¸­å¾ˆå¤šæ™‚å€™ä¸¦ç„¡æ³•å¾ \(p(\theta \mid y)\) é€™å€‹ distribution æŠ½æ¨£ï¼Œè¦ä¸å°±æ˜¯ä¸çŸ¥é“é€™å€‹ distributionï¼Œè¦ä¸å°±æ˜¯é€™å€‹ distribution çˆ†ç‚¸è¤‡é›œå•Šã€‚</p>

<p>æ‰€ä»¥èªªï¼Œå“ªæœ‰é€™éº¼å¥½çš„äº‹ï¼Ÿ</p>

<p>é€™æ™‚å€™å¯ä»¥æ¡ç”¨å…¶ä»–çš„æŠ½æ¨£æ–¹æ³•ï¼Œè­¬å¦‚ï¼Œ<em>rejection sampling</em>, <em>importance sampling</em> å’Œæœ¬æ–‡çš„é‡é» <em>MCMC</em>ã€‚</p>

<hr />

<p><strong>Markov Chain</strong></p>

<ul>
  <li>
    <p>Markov Chain (é¦¬å¯å¤«éŠ)ï¼šA Markov chain is a sequence \(X_0, X_1, ...\) of random variables such that the distribution of the next value depends only on the current on (and parameters). ç¾åœ¨æœ‰ä¸€éš¨æ©Ÿè®Šæ•¸æ•¸åˆ— \(X_0, X_1, ...\)ï¼Œä¸”æ¯ä¸€å€‹è®Šæ•¸åªå’Œå‰ä¸€å€‹è®Šæ•¸æœ‰é—œï¼Œä¹Ÿå°±æ˜¯ \(X_{t+1}\) ä¾†è‡ª \(p(X_{t+1} \mid X_t)\)ï¼Œåƒé€™æ¨£çš„æ•¸åˆ—æˆ‘å€‘å°±ç¨±ç‚ºé¦¬å¯å¤«éŠã€‚</p>
  </li>
  <li>
    <p>\(p(X_{t+1} \mid X_t)\) è¢«ç¨±ç‚ºé€™å€‹é¦¬å¯å¤«éŠçš„è½‰æ›æ ¸å¿ƒ (transition kernel)</p>
  </li>
  <li>
    <p>A Markov chain is stationary, with stationary distribution \(Î¦, if ~\forall k ~ X_k  \sim Î¦\)</p>
  </li>
  <li>
    <p>One shows (not trivial in general) that under <em>certain</em> conditions a Markov chain will converge to the stationary distribution in the limit. åœ¨ä¸€èˆ¬æ¢ä»¶å‡è¨­åº•ä¸‹ï¼Œé¦¬å¯å¤«éŠçš„è®Šæ•¸åˆ†é…å°‡æ”¶æ–‚åˆ°ç›®æ¨™æ©Ÿç‡å‡½æ•¸ \(\pi(Â·)\) ä¸¦ä¸”èˆ‡ \(X_0\) çš„é¸æ“‡ç„¡é—œã€‚</p>
  </li>
</ul>

<p><em>Monte Carlo Integration</em>å¯ä»¥çœ‹<a href="https://www.youtube.com/watch?v=MKnjsqYVG4Y">é€™è£¡</a></p>

<hr />

<p>Reference:
<br />
<a href="https://www.youtube.com/watch?v=3ZmW_7NXVvk">(ML 18.1) Markov chain Monte Carlo (MCMC) introduction-12eZWG0Z5gY.mp4</a>
<br />
<a href="http://web.ntpu.edu.tw/~ccw/statmath/M_mcmc.pdf">The Markov Chain Monte Carlo Simulations</a>
<br /> 
LinkÃ¶ping University - 732A90 Computational Statistics 2019 Lecture 4 slide
<br />
<a href="https://zhuanlan.zhihu.com/p/25610149">[æ•°æ®åˆ†æ] Markov Chain Monte Carlo</a>
<br />
<a href="https://www.youtube.com/watch?v=s8w8AsFK77c&amp;list=PLyAft-JyjIYq2SLTHO2ptmx-cChbE5GBm">å¾äº¦è¾¾æœºå™¨å­¦ä¹ è¯¾ç¨‹ Markov Chain Monte Carlo</a>
<br />
<a href="http://www.cnblogs.com/pinard/p/6625739.html">MCMC(ä¸€)è’™ç‰¹å¡ç½—æ–¹æ³•</a></p>
:ET