<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>M.C. Shih &middot; BLOG</title>  
  

  <!-- CSS -->
  <link rel="stylesheet" href="/blog/public/css/poole.css">
  <link rel="stylesheet" href="/blog/public/css/syntax.css">
  <link rel="stylesheet" href="/blog/public/css/hyde.css">
  <link rel="stylesheet" href="/blog/public/css/custom.css">
  <link rel="stylesheet" href="/blog/public/css/fontawesome-all.css">
  <link rel="stylesheet" href="/blog/public/css/fontawesome-all.min.css">
  <!-- <link href="https://use.fontawesome.com/releases/v5.0.8/css/all.css" rel="stylesheet"> -->


  <!--<link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface"> -->

  <!-- Icons -->
  <link rel="apple-touch-icon" sizes="16x16" href="/blog/public/apple-touch-icon-16-precomposed.png">
  <link rel="apple-touch-icon" sizes="24x24" href="/blog/public/apple-touch-icon-24-precomposed.png">
  <link rel="apple-touch-icon" sizes="32x32" href="/blog/public/apple-touch-icon-32-precomposed.png">
  <link rel="apple-touch-icon" sizes="48x48" href="/blog/public/apple-touch-icon-48-precomposed.png">
  <link rel="apple-touch-icon" sizes="57x57" href="/blog/public/apple-touch-icon-57-precomposed.png">
  <link rel="apple-touch-icon" sizes="64x64" href="/blog/public/apple-touch-icon-64-precomposed.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/blog/public/apple-touch-icon-72-precomposed.png"> 
  <link rel="apple-touch-icon" sizes="114x114" href="/blog/public/apple-touch-icon-114-precomposed.png"> 
  <link rel="apple-touch-icon" sizes="120x120" href="/blog/public/apple-touch-icon-120-precomposed.png"> 
  <link rel="apple-touch-icon" sizes="144x144" href="/blog/public/apple-touch-icon-144-precomposed.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/blog/public/apple-touch-icon-152-precomposed.png">
  <link rel="apple-touch-icon" sizes="512x512" href="/blog/public/apple-touch-icon-512-precomposed.png">
  <link rel="shortcut icon" href="/blog/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/blogblog/atom.xml">
  <!-- 數學符號 -->
  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
</head>


  <body>
  	
    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/blog/">
          M.C. Shih
        </a>
        <img src="/blog/img/headshot.png" alt="Author Image" class="headshot">
      </h1>
      <p class="lead">Just for learning.</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/blog/">Blog</a>

      

      
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/blog/about/">About</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="/blog/archive/">Archives</a>
          
        
      
        
      
        
          
            <a class="sidebar-nav-item" href="/blog/category/">Category</a>
          
        
      
        
          
        
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/blog/search/">Search</a>
          
        
      
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      

    </nav>
    <div class="links">
      <ul>
        <li><a href="https://shihs.github.io" class="homepage" target="_blank"><img src="/blog/img/link%20icon/iconmonstr-home-6-240.png"></a></li>
        <li><a href="https://github.com/shihs" class="github" target="_blank"><img src="/blog/img/link%20icon/iconmonstr-github-3-240.png"></a></li>
        <li><a href="https://www.linkedin.com/in/min-chun-shih-6647779a/" class="linkedin" target="_blank"><img src="/blog/img/link%20icon/iconmonstr-linkedin-3-240.png"></a></li>
        <li><a href="https://www.instagram.com/itakephotos_tw/" class="instagram" target="_blank"><img src="/blog/img/link%20icon/iconmonstr-instagram-8-240.png"></a></li>
        <li><a href="https://www.flickr.com/photos/mcshihs/" class="flickr" target="_blank"><img src="/blog/img/link%20icon/iconmonstr-flickr-3-240.png"></a></li>
      </ul>
    </div>
    

    <p class = "rights">&copy; 2022. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="posts" id="begin">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/blog/python/2019/01/02/Python-%E8%AE%80%E5%8F%96%E8%88%87%E5%AF%AB%E5%85%A5xlsx%E6%AA%94%E6%A1%88/">
        [Python]讀取與寫入xlsx檔案
      </a>
    </h1>

    <div class="post-info">
      <!-- <span class="post-date">Posted by Shihs on January 2, 2019</span> -->
      <i class="fas fa-calendar-alt"></i>
      <span class="post-date">January 2, 2019</span>
      <span class="post-categories">
      <!-- <i class="fas fa-tag"></i> -->
      <!-- <i class="far fa-book"></i> -->
      <i class="fas fa-box"></i>
      
      
        <a target="_blank" href="/blog/category/#Python">Python</a>
        
      
    </span>

    </div>
    <!-- <p>這裡要介紹使用 pandas 套件讀取與寫入 xlsx 檔案。</p>

<p>在開始前請先安裝 pandas 套件，</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip install pandas
</code></pre></div></div>

<hr />

<p><strong>讀取檔案</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s">"filename.xlsx"</span><span class="p">,</span> <span class="n">header</span> <span class="o">=</span> <span class="bp">None</span><span class="p">)</span>

<span class="c"># 獲取列數</span>
<span class="n">rows</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c"># 獲取儲存格內容</span>
<span class="n">df</span><span class="o">.</span><span class="n">iat</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

<span class="c"># 修改儲存格內容</span>
<span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="s">"test"</span>
<span class="c"># 但修改後必須要儲存才會修正檔案內容</span>
<span class="c"># df.to_excel('test_result.xlsx', sheet_name = 'sheet1')</span>
</code></pre></div></div>

<p>若在執行以上程式碼時產生錯誤訊息：</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Pandas pd.read_excel giving ImportError: Install xlrd &gt;= 0.9.0 for Excel support
</code></pre></div></div>

<p>這時候只要安裝 xlrd 套件就能解決問題。</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip install xlrd
</code></pre></div></div>

<hr />

<p><strong>寫入檔案</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="c"># Create a Pandas dataframe from some data.</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">'Data'</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">45</span><span class="p">]})</span>

<span class="c"># Create a Pandas Excel writer using XlsxWriter as the engine.</span>
<span class="n">writer</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">ExcelWriter</span><span class="p">(</span><span class="s">'pandas_simple.xlsx'</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s">'xlsxwriter'</span><span class="p">)</span>

<span class="c"># Convert the dataframe to an XlsxWriter Excel object.</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="n">writer</span><span class="p">,</span> <span class="n">sheet_name</span><span class="o">=</span><span class="s">'Sheet1'</span><span class="p">)</span>

<span class="c"># Close the Pandas Excel writer and output the Excel file.</span>
<span class="n">writer</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
</code></pre></div></div>

<p>以上的程式碼是參考<a href="https://xlsxwriter.readthedocs.io/example_pandas_simple.html#">這裡</a>。</p>

<p>我存的檔案內容是中文，這時候產生了像這樣的錯誤訊息</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Python pandas to excel UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 11
</code></pre></div></div>
<p>只要將 <code class="highlighter-rouge">pd.ExcelWriter</code> 裡的參數 <code class="highlighter-rouge">engine='xlsxwriter'</code> 改成 <code class="highlighter-rouge">engine='openpyxl'</code> 就可以了。</p>

<hr />

<p>Reference:
<br />
<a href="https://xlsxwriter.readthedocs.io/example_pandas_simple.html">Example: Pandas Excel example</a>
<br />
<a href="https://stackoverflow.com/questions/48066517/python-pandas-pd-read-excel-giving-importerror-install-xlrd-0-9-0-for-excel">Python: Pandas pd.read_excel giving ImportError: Install xlrd &gt;= 0.9.0 for Excel support</a>
<br />
<a href="https://stackoverflow.com/questions/47698744/python-pandas-to-excel-unicodedecodeerror-ascii-codec-cant-decode-byte-0xe2">Python pandas to excel UnicodeDecodeError: ‘ascii’ codec can’t decode byte 0xe2 in position 11</a>
<br />
<a href="https://ithelp.ithome.com.tw/articles/10197119">PYTHON pandas 操作Excel 基本介紹</a></p>

 -->
    <div class="post-excerpt"><p>這裡要介紹使用 pandas 套件讀取與寫入 xlsx 檔案。</p>

</div>

    <div class="bookmark">
      <!-- <i class="far fa-comments"></i> -->
      <i class="fas fa-comments"></i>
      <span>
        


<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
var disqus_config = function () {
        // this.page.url = '/blog//python/2019/01/02/Python-%E8%AE%80%E5%8F%96%E8%88%87%E5%AF%AB%E5%85%A5xlsx%E6%AA%94%E6%A1%88/#disqus_thread';
        this.page.identifier = '/python/2019/01/02/Python-%E8%AE%80%E5%8F%96%E8%88%87%E5%AF%AB%E5%85%A5xlsx%E6%AA%94%E6%A1%88/';
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://mcshihs.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>



        <a href="/blog//python/2019/01/02/Python-%E8%AE%80%E5%8F%96%E8%88%87%E5%AF%AB%E5%85%A5xlsx%E6%AA%94%E6%A1%88/#disqus_thread" data-disqus-identifier="/python/2019/01/02/Python-%E8%AE%80%E5%8F%96%E8%88%87%E5%AF%AB%E5%85%A5xlsx%E6%AA%94%E6%A1%88/">0 Comments</a>
      </span>

    </div>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/blog/python/2019/01/02/Python-%E5%85%A8%E5%BD%A2%E8%88%87%E5%8D%8A%E5%BD%A2%E8%BD%89%E6%8F%9B/">
        [Python]全形與半形轉換
      </a>
    </h1>

    <div class="post-info">
      <!-- <span class="post-date">Posted by Shihs on January 2, 2019</span> -->
      <i class="fas fa-calendar-alt"></i>
      <span class="post-date">January 2, 2019</span>
      <span class="post-categories">
      <!-- <i class="fas fa-tag"></i> -->
      <!-- <i class="far fa-book"></i> -->
      <i class="fas fa-box"></i>
      
      
        <a target="_blank" href="/blog/category/#Python">Python</a>
        
      
    </span>

    </div>
    <!-- <p>因為全形字元的 unicode 編碼從 65281~65374，而半形字元的 unicode 編碼從 33~126，也就是同樣的字在全形與半形數字會差 65248。</p>

<p>例如，半形的驚嘆號（!）是 unicode 編碼是 33，則全形的驚嘆號（！）unicode 就會編碼是 33 + 65248 = 65281</p>

<p>但要將數字解析成半形時是使用 <code class="highlighter-rouge">chr()</code> function，而全形則是使用 <code class="highlighter-rouge">unichr()</code> function。</p>

<p>以下將 33~126 全部列出來，並轉換成全形。</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">33</span><span class="p">,</span><span class="mi">127</span><span class="p">):</span>
	<span class="k">print</span> <span class="n">i</span><span class="p">,</span> <span class="nb">chr</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">i</span><span class="o">+</span><span class="mi">65248</span><span class="p">,</span> <span class="nb">unichr</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">65248</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s">"utf-8"</span><span class="p">)</span>

</code></pre></div></div>

<p>結果，</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>33 ! 65281 ！
34 " 65282 ＂
35 # 65283 ＃
36 $ 65284 ＄
37 % 65285 ％
38 &amp; 65286 ＆
39 ' 65287 ＇
40 ( 65288 （
41 ) 65289 ）
42 * 65290 ＊
43 + 65291 ＋
44 , 65292 ，
45 - 65293 －
46 . 65294 ．
47 / 65295 ／
48 0 65296 ０
49 1 65297 １
50 2 65298 ２
51 3 65299 ３
52 4 65300 ４
53 5 65301 ５
54 6 65302 ６
55 7 65303 ７
56 8 65304 ８
57 9 65305 ９
58 : 65306 ：
59 ; 65307 ；
60 &lt; 65308 ＜
61 = 65309 ＝
62 &gt; 65310 ＞
63 ? 65311 ？
64 @ 65312 ＠
65 A 65313 Ａ
66 B 65314 Ｂ
67 C 65315 Ｃ
68 D 65316 Ｄ
69 E 65317 Ｅ
70 F 65318 Ｆ
71 G 65319 Ｇ
72 H 65320 Ｈ
73 I 65321 Ｉ
74 J 65322 Ｊ
75 K 65323 Ｋ
76 L 65324 Ｌ
77 M 65325 Ｍ
78 N 65326 Ｎ
79 O 65327 Ｏ
80 P 65328 Ｐ
81 Q 65329 Ｑ
82 R 65330 Ｒ
83 S 65331 Ｓ
84 T 65332 Ｔ
85 U 65333 Ｕ
86 V 65334 Ｖ
87 W 65335 Ｗ
88 X 65336 Ｘ
89 Y 65337 Ｙ
90 Z 65338 Ｚ
91 [ 65339 ［
92 \ 65340 ＼
93 ] 65341 ］
94 ^ 65342 ＾
95 _ 65343 ＿
96 ` 65344 ｀
97 a 65345 ａ
98 b 65346 ｂ
99 c 65347 ｃ
100 d 65348 ｄ
101 e 65349 ｅ
102 f 65350 ｆ
103 g 65351 ｇ
104 h 65352 ｈ
105 i 65353 ｉ
106 j 65354 ｊ
107 k 65355 ｋ
108 l 65356 ｌ
109 m 65357 ｍ
110 n 65358 ｎ
111 o 65359 ｏ
112 p 65360 ｐ
113 q 65361 ｑ
114 r 65362 ｒ
115 s 65363 ｓ
116 t 65364 ｔ
117 u 65365 ｕ
118 v 65366 ｖ
119 w 65367 ｗ
120 x 65368 ｘ
121 y 65369 ｙ
122 z 65370 ｚ
123 { 65371 ｛
124 | 65372 ｜
125 } 65373 ｝
126 ~ 65374 ～

</code></pre></div></div>

<hr />

<p>Reference:
<br />
<a href="https://codertw.com/程式語言/367570/">Python實現全形半形字元互轉的方法</a></p>
 -->
    <div class="post-excerpt"><p>因為全形字元的 unicode 編碼從 65281~65374，而半形字元的 unicode 編碼從 33~126，也就是同樣的字在全形與半形數字會差 65248。</p>

</div>

    <div class="bookmark">
      <!-- <i class="far fa-comments"></i> -->
      <i class="fas fa-comments"></i>
      <span>
        


<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
var disqus_config = function () {
        // this.page.url = '/blog//python/2019/01/02/Python-%E5%85%A8%E5%BD%A2%E8%88%87%E5%8D%8A%E5%BD%A2%E8%BD%89%E6%8F%9B/#disqus_thread';
        this.page.identifier = '/python/2019/01/02/Python-%E5%85%A8%E5%BD%A2%E8%88%87%E5%8D%8A%E5%BD%A2%E8%BD%89%E6%8F%9B/';
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://mcshihs.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>



        <a href="/blog//python/2019/01/02/Python-%E5%85%A8%E5%BD%A2%E8%88%87%E5%8D%8A%E5%BD%A2%E8%BD%89%E6%8F%9B/#disqus_thread" data-disqus-identifier="/python/2019/01/02/Python-%E5%85%A8%E5%BD%A2%E8%88%87%E5%8D%8A%E5%BD%A2%E8%BD%89%E6%8F%9B/">0 Comments</a>
      </span>

    </div>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/blog/machine%20learning/2018/12/27/Machine-Learning-Linear-Regression/">
        [Machine Learning]Linear Regression
      </a>
    </h1>

    <div class="post-info">
      <!-- <span class="post-date">Posted by Shihs on December 27, 2018</span> -->
      <i class="fas fa-calendar-alt"></i>
      <span class="post-date">December 27, 2018</span>
      <span class="post-categories">
      <!-- <i class="fas fa-tag"></i> -->
      <!-- <i class="far fa-book"></i> -->
      <i class="fas fa-box"></i>
      
      
        <a target="_blank" href="/blog/category/#Machine Learning">Machine Learning</a>
        
      
    </span>

    </div>
    <!-- <p>Linear Regression 屬於 Supervised Learning(監督式學習)，用來預測連續型(continuous)的變數。</p>

<hr />

<h2 id="simple-linear-regression">Simple Linear Regression</h2>

<p>Simple Linear Regression 假設 \(X, Y\) 存在線性關係，且可以使用以下的式子來表示 \(X, Y\)的關係。</p>

<blockquote>

  <script type="math/tex; mode=display">Y \approx \beta_0 + \beta_1 X</script>
</blockquote>

<p>而現實中我們無法知道參數 \(\beta_0, \beta_1\)，這時候我們會使用 train data 找出估計參數 \(\hat{\beta_0}, \hat{\beta_1}\)。簡單線性回歸的估計式可以寫成，</p>

<blockquote>

  <script type="math/tex; mode=display">\hat{y} = \hat{\beta_0} + \hat{\beta_1} x</script>
</blockquote>

<p>其中，\(\hat{y}\) 是當 \(X = x\) 時 \(Y\)的預測值。</p>

<hr />

<p><strong>Estimating the Coefficients</strong></p>

<p>現在有一堆 data， \((x_i, y_i), \thinspace i = 1, 2, 3, …, n\)，根據上面的迴歸式可以將這些 data 表示成，</p>

<script type="math/tex; mode=display">y_i \approx \hat{\beta_0} + \hat{\beta_1} x_i, \thinspace for \thinspace i = 1, 2, 3, ..., n</script>

<p>已經知道迴歸模型可以用上面的式子表示，那現在的任務是要找到 \(\hat{\beta_0}\) 和 \(\hat{\beta_1}\)，只要找到這兩個參數就可以預測 \(y\) 了。</p>

<p>找 \(\hat{\beta_0}, \hat{\beta_1}\) 的方法叫 <strong>The Least Square Method</strong>（最小平方法）。</p>

<p><img src="http://localhost:4000/blog/img/posts/linear%20regression.png" alt="linear regression.png" height="450px" width="600px" /></p>

<p>以上圖為例，紅色的點為 observations，深藍色的線是用最小平方法找到的迴歸線。</p>

<hr />

<p><strong>The Least Square Method 是什麼？</strong></p>

<p>式子 \( \hat{y_i} = \hat{\beta_0} + \hat{\beta_1} x_i \) 為 \(X = x_i\) 時 \(Y\) 的預測值。</p>

<p>我們使用 Residual(殘差) 來看這個預測的結果與實際數值的差距，定義為 \(e_i = y_i - \hat{y_i}\) (上圖中紅點到深藍色線的灰色線段們)。</p>

<p>將所有 Residual 相加便能</p>

<p>RSS =</p>

<hr />

<p>Reference:
<br />
<a href="http://www-bcf.usc.edu/~gareth/ISL/">An Introduction to Statistical Learning with Applications in R</a></p>

 -->
    <div class="post-excerpt"><p>Linear Regression 屬於 Supervised Learning(監督式學習)，用來預測連續型(continuous)的變數。</p>

</div>

    <div class="bookmark">
      <!-- <i class="far fa-comments"></i> -->
      <i class="fas fa-comments"></i>
      <span>
        


<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
var disqus_config = function () {
        // this.page.url = '/blog//machine%20learning/2018/12/27/Machine-Learning-Linear-Regression/#disqus_thread';
        this.page.identifier = '/machine%20learning/2018/12/27/Machine-Learning-Linear-Regression/';
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://mcshihs.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>



        <a href="/blog//machine%20learning/2018/12/27/Machine-Learning-Linear-Regression/#disqus_thread" data-disqus-identifier="/machine%20learning/2018/12/27/Machine-Learning-Linear-Regression/">0 Comments</a>
      </span>

    </div>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/blog/machine%20learning/2018/12/09/Machine-Learning-Regression-splines/">
        [Machine Learning]Regression splines
      </a>
    </h1>

    <div class="post-info">
      <!-- <span class="post-date">Posted by Shihs on December 9, 2018</span> -->
      <i class="fas fa-calendar-alt"></i>
      <span class="post-date">December 9, 2018</span>
      <span class="post-categories">
      <!-- <i class="fas fa-tag"></i> -->
      <!-- <i class="far fa-book"></i> -->
      <i class="fas fa-box"></i>
      
      
        <a target="_blank" href="/blog/category/#Machine Learning">Machine Learning</a>
        
      
    </span>

    </div>
    <!-- <p><img src="http://localhost:4000/blog/img/posts/splines%20scatter%20plot.png" alt="splines scatter plot.png" height="380px" width="600px" /></p>

<p>上圖是一個 x, y 的分佈圖，紅線是這些點分部的方程式。但現實中，我們並無法真的知道紅線的方程式，我們可能使用一次方程式、二次方程式甚至更高次方的方程式去嘗試（如下圖
）。
<img src="http://localhost:4000/blog/img/posts/splines%20line.png" alt="splines line.png" height="380px" width="600px" /></p>

<p>我們可以將擬合的多項式方程式（polynomial function）寫成，</p>

<p>\(y = \beta_0 + \beta_1 x^1 + \beta_2 x^2 + … + \beta_n x^n + \epsilon\)</p>

<p>但只是一味的提高多項式的次方只是增加模型的複雜度會導致 overfitting 的問題，在 testing data 上的結果也不會太好。</p>

<p>這時候我們可以使用 Piecewise 將 data 劃分成多個區間，根據每個區間的 data 給予一個模型去擬合。</p>

<hr />

<p><strong>Basis function</strong></p>

<p>\(y_i = \beta_0 + \beta_1 b_1(x_i) + \beta_2 b_2(x_i) + … + \beta_n b_n(x_i) + \epsilon_i\)</p>

<p>透過 \(b_1(X)\)、\(b_2(X)\)、……、\(b_n(X)\) 可以將非線性的自變量轉換成線性。</p>

<hr />

<p><strong>Piecewise Function</strong></p>

<p>將 data 劃分多個區段後，每個區段再各自找到可以擬合的 model，model 可以是一次方程式、二次方程式或是三次方程式等等，不過三次方最常使用。</p>

<p>如下圖每個區段都是用一次方程式去擬合。\(\xi\) 為區段的分隔點，稱為 knot，每個分段函數稱為 piecewise function。</p>

<p><img src="http://localhost:4000/blog/img/posts/piecewise%20linear.png" alt="piecewise linear.png" height="600px" width="500px" />
From: 《Elements of Statistical Learning》</p>

<p>但這些 piecewise function 是有條件的。
<br />
雖然 piecewise function 是每個區段各自擬合出來的 function，但所有區段 function 必須整個為連續，也就是在 \(\xi\) 的交界處的值必須相同。</p>

<hr />

<p><strong>Cubic Spline</strong></p>

<p>這裡則是使用三次方程式。</p>

<p><img src="http://localhost:4000/blog/img/posts/piecewise%20cubic%20polynomials.png" alt="piecewise cubic polynomials.png" height="600px" width="500px" />
From: 《Elements of Statistical Learning》</p>

<p>cubic spline 除了邊界的值相同外，還必須要一階和二階倒數相同。</p>

<p>看上圖左上的圖加上邊界連續後成為右上，雖然看起來是連續的函數，但並不是完美的曲線，如果再加上一階導數相同就變成左下，再加上二階導數就可以畫出右下的圖。</p>

<hr />

<p>這個 R code 是畫出最上面圖的程式碼，使用 <a href="https://www.youtube.com/watch?v=bESJ81dyYro">Introduction to Splines</a> 裡頭的範例。</p>

<div class="language-R highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">set.seed</span><span class="p">(</span><span class="m">100</span><span class="p">)</span><span class="w">

</span><span class="c1"># function</span><span class="w">
</span><span class="n">f</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="n">f_x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.2</span><span class="o">*</span><span class="n">x</span><span class="o">^</span><span class="m">11</span><span class="o">*</span><span class="p">(</span><span class="m">10</span><span class="o">*</span><span class="p">(</span><span class="m">1</span><span class="o">-</span><span class="n">x</span><span class="p">))</span><span class="o">^</span><span class="m">6</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">10</span><span class="o">*</span><span class="p">(</span><span class="m">10</span><span class="o">*</span><span class="n">x</span><span class="p">)</span><span class="o">^</span><span class="m">3</span><span class="o">*</span><span class="p">(</span><span class="m">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span><span class="o">^</span><span class="m">10</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">seq</span><span class="p">(</span><span class="n">from</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">length</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span><span class="p">)</span><span class="w">
</span><span class="n">f_x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w">
</span><span class="n">eps</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rnorm</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="c1"># epsilon</span><span class="w">
</span><span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">f_x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">eps</span><span class="w">

</span><span class="n">d</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.frame</span><span class="p">(</span><span class="w">
  </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w">
  </span><span class="n">f_x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f_x</span><span class="p">,</span><span class="w">
  </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="w">
</span><span class="p">)</span><span class="w">

</span><span class="c1"># plot</span><span class="w">
</span><span class="n">ggplot</span><span class="p">(</span><span class="n">d</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_point</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> 
  </span><span class="n">geom_line</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">f_x</span><span class="p">),</span><span class="w"> </span><span class="n">colour</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"red"</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.8</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">theme_bw</span><span class="p">()</span><span class="w">

</span><span class="n">ggplot</span><span class="p">(</span><span class="n">d</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_point</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> 
  </span><span class="n">geom_smooth</span><span class="p">(</span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"lm"</span><span class="p">,</span><span class="w"> </span><span class="n">se</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">stat_smooth</span><span class="p">(</span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"lm"</span><span class="p">,</span><span class="w"> </span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">I</span><span class="p">(</span><span class="n">x</span><span class="o">^</span><span class="m">2</span><span class="p">),</span><span class="w"> </span><span class="n">se</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">,</span><span class="w"> </span><span class="n">colour</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"green"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="c1"># stat_smooth(method = "lm", formula = y ~ x + I(x^2) + I(x^3), se = FALSE, colour = "gold1") +</span><span class="w">
  </span><span class="c1"># stat_smooth(method = 'loess', se = FALSE, colour = "red") +</span><span class="w">
  </span><span class="n">theme_bw</span><span class="p">()</span><span class="w">
</span></code></pre></div></div>

<hr />

<p>Reference:
<br />
<a href="https://zhuanlan.zhihu.com/p/34825299">一文读懂回归样条（regression splines），附Python代码</a>
<br />
<a href="https://www.youtube.com/watch?v=bESJ81dyYro">Introduction to Splines</a>
<br />
<a href="https://www.youtube.com/watch?v=V1JRs6AP1AI">Spline Regression | Non Linear Model | Polynomial Regression</a>
<br />
<a href="https://zh.wikipedia.org/wiki/样条函数">wikipedia - 樣條函數</a>
<br />
<a href="https://datascienceplus.com/cubic-and-smoothing-splines-in-r/">Cubic and Smoothing Splines in R</a>
<br />
<a href="http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf">《An Introduction to Statistical Learning with Applications in R》</a></p>
 -->
    <div class="post-excerpt"><p><img src="http://localhost:4000/blog/img/posts/splines%20scatter%20plot.png" alt="splines scatter plot.png" height="380px" width="600px" /></p>

</div>

    <div class="bookmark">
      <!-- <i class="far fa-comments"></i> -->
      <i class="fas fa-comments"></i>
      <span>
        


<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
var disqus_config = function () {
        // this.page.url = '/blog//machine%20learning/2018/12/09/Machine-Learning-Regression-splines/#disqus_thread';
        this.page.identifier = '/machine%20learning/2018/12/09/Machine-Learning-Regression-splines/';
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://mcshihs.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>



        <a href="/blog//machine%20learning/2018/12/09/Machine-Learning-Regression-splines/#disqus_thread" data-disqus-identifier="/machine%20learning/2018/12/09/Machine-Learning-Regression-splines/">0 Comments</a>
      </span>

    </div>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/blog/machine%20learning/2018/12/08/Machine-Learning-Principal-Component-Analysis(PCA)/">
        [Machine Learning]Principal Component Analysis(PCA)
      </a>
    </h1>

    <div class="post-info">
      <!-- <span class="post-date">Posted by Shihs on December 8, 2018</span> -->
      <i class="fas fa-calendar-alt"></i>
      <span class="post-date">December 8, 2018</span>
      <span class="post-categories">
      <!-- <i class="fas fa-tag"></i> -->
      <!-- <i class="far fa-book"></i> -->
      <i class="fas fa-box"></i>
      
      
        <a target="_blank" href="/blog/category/#Machine Learning">Machine Learning</a>
        
      
    </span>

    </div>
    <!-- <p><img src="http://localhost:4000/blog/img/posts/PCA.png" alt="PCA.png" height="260px" width="600px" /></p>

<p>From: «Pattern Recognition and Machine Learning» P.561</p>

<hr />

<p><strong>What is PCA?</strong></p>

<p>Principal Component Analysis(PCA)，中文翻作「主成分分析」。</p>

<p>PCA 是一種將多維度降維的方法。
<br />
一個變數其實可能是多個潛在變因（laten variables）組成，但我們無法實際測量出那些 laten variables，而 PCA 就是要拆解出影響較大的變因。使用較少的變數解釋多個 variables。</p>

<p>舉個例子，股市的點數上上下下，我們所能觀測到的是點數這個變數，但其實影響點數變動的潛在變因可能包含了很多市場因素，且每個因素可能又是互相影響。</p>

<p>如果用數學符號表示，\(x_i\) 是我們有的變數，\(z_i\) 是裡頭含有的潛在變因，\(x_i\) 是 \(z_i\) 的線性組合（linear combination）。
<br />
\(x_1 = a_{11} z_1 + a_{12} z_2 + a_{13} z_3 + \epsilon_1\)
<br />
\(x_2 = a_{21} z_1 + a_{22} z_2 + a_{23} z_3 + \epsilon_2\)
<br />
\(x_3 = a_{31} z_1 + a_{32} z_2 + a_{33} z_3 + \epsilon_3\)
<br />
……</p>

<p>可以將上式改寫成，
<br />
\(z_1 = x_1 u_{i1} + x_2 u_{i2} + x_3 u_{i3}\)
<br />
……</p>

<hr />

<p><strong>如何降維？</strong></p>

<p>根據 «Pattern Recognition and Machine Learning» 這本書第 561 頁給了 PCA 兩種定義</p>
<ol>
  <li>PCA can be defined as the orthogonal projection of the data onto a lower dimensional linear space, known as the principal subspace, such that the variance of the projected data is maximized (Hotelling, 1933).</li>
  <li>PCA can be defined as the linear projection that minimizes the average projection cost, defined as the mean squared distance tbtween the data points and their projections (Pearson, 1901).</li>
</ol>

<p>可以用上圖來理解，或是 <a href="https://www.youtube.com/watch?v=FgakZw6K1QQ#t=4m35s">StatQuest: Principal Component Analysis (PCA), Step-by-Step</a> 這段。</p>

<p>根據上面的定義，可以看到，降維的方法是要做 <a href="https://www.khanacademy.org/math/linear-algebra/alternate-bases/orthogonal-projections/v/linear-algebra-projections-onto-subspaces">orthogonal projection</a>，且找到投影向量讓投影後的資料變異量最大。</p>

<p>這邊我使用 <a href="https://www.youtube.com/watch?v=FgakZw6K1QQ">StatQuest: Principal Component Analysis (PCA), Step-by-Step</a> 影片的內容來介紹。</p>

<ul>
  <li>maximized 什麼？
<img src="http://localhost:4000/blog/img/posts/PCA_maximizing.png" alt="PCA_maximizing.png" height="320px" width="600px" /></li>
</ul>

<p>假如現在座標上有個綠色的點，以座標\((0, 0)\)原點，其長度為 a（影片沒有表示這是 a 向量，方便起見，後面以 a, b, c 向量表示），c 向量為 a 向量的投影方向與長度。根據畢氏定理，可以畫出一個正三角形，現在三角形的三邊長分別為 a, b, c（因為我懶得再圖上修正了，現在又變回長度）。而 PCA 要找的投影向量就是，最小化 \(b^2\) 的值，或是最大化 \(c^2\) 的值。</p>

<ul>
  <li>投影</li>
</ul>

<p><img src="http://localhost:4000/blog/img/posts/PCA_projection.png" alt="PCA_projection.png" height="320px" width="600px" /></p>

<p>根據上圖，這個二維座標上有好幾個點，我們現在就是要找到一條能讓投影後 variance 最大的投影向量（紅色虛線），如下圖。要找到 SS（eigenvalue） 最小的投影向量。</p>

<p><img src="http://localhost:4000/blog/img/posts/SS.png" alt="SS.png" height="320px" width="600px" /></p>

<p>在投影前，我們會先將資料平移 \(x_i - \mu_i\)，也就是不改變點之間的相對位置，這樣不但不會影響找投影向量的結果，在計算上也比較容易。</p>

<hr />

<p><strong>Variation 變異量</strong></p>

<p>變異量 = \(SS/(n-1), n \)是點的數量</p>

<p>有了變異量以後，我們通常會想要知道每個投影向量的變異量占比。</p>

<p>假如現在有 PC1 其變異量為 15，PC2 的變異量為 3，則 PC1 與 PC2 的變異量總和為 18。</p>

<p>所以 PC1 = 15*100%/18 = 83%，PC2 = 3*100%/18 = 17%。</p>

<p>在做 PCA 的時候，我們會根據轉換的 \(PC_i\) 的比重，來決定要考慮要使用幾個 \(PC_i\)。
如果可以解釋百分之九十基本上就可以拿來使用。</p>

<p>假如今天有一筆多維度的資料，但轉換後 PC1 與 PC2 可以表示百分之九十的變異量，那麼這時候只要使用 PC1 與 PC2 就好，且還可以在平面座標上看點的分佈。</p>

<hr />

<p>基本上 PCA 就是在做座標變換，將原變數投影成新變數。接著以最少的新變數來代表原始資料最大的成分（variation 涵蓋量最大）。</p>

<p>其原則如下</p>
<ul>
  <li>新變數是原變數的線性組合</li>
  <li>保留原變數間的最大變異量（variance）</li>
</ul>

<hr />

<p>Reference:
<br />
<a href="https://www.youtube.com/watch?v=FgakZw6K1QQ">StatQuest: Principal Component Analysis (PCA), Step-by-Step</a>
<br />
<a href="https://medium.com/@chih.sheng.huang821/機器-統計學習-主成分分析-principle-component-analysis-pca-58229cd26e71">機器/統計學習:主成分分析(Principal Component Analysis, PCA)</a>
<br />
<a href="https://zh.wikipedia.org/wiki/主成分分析">wikipedia - 主成分分析</a>
<br />
The Elements of Statistical Learning
<br />
Pattern Recognition and Machine Learning</p>
 -->
    <div class="post-excerpt"><p><img src="http://localhost:4000/blog/img/posts/PCA.png" alt="PCA.png" height="260px" width="600px" /></p>

</div>

    <div class="bookmark">
      <!-- <i class="far fa-comments"></i> -->
      <i class="fas fa-comments"></i>
      <span>
        


<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
var disqus_config = function () {
        // this.page.url = '/blog//machine%20learning/2018/12/08/Machine-Learning-Principal-Component-Analysis(PCA)/#disqus_thread';
        this.page.identifier = '/machine%20learning/2018/12/08/Machine-Learning-Principal-Component-Analysis(PCA)/';
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://mcshihs.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>



        <a href="/blog//machine%20learning/2018/12/08/Machine-Learning-Principal-Component-Analysis(PCA)/#disqus_thread" data-disqus-identifier="/machine%20learning/2018/12/08/Machine-Learning-Principal-Component-Analysis(PCA)/">0 Comments</a>
      </span>

    </div>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/blog/machine%20learning/2018/12/03/Machine-Learning-Boosting-and-Adaboost/">
        [Machine Learning]Boosting and Adaboost
      </a>
    </h1>

    <div class="post-info">
      <!-- <span class="post-date">Posted by Shihs on December 3, 2018</span> -->
      <i class="fas fa-calendar-alt"></i>
      <span class="post-date">December 3, 2018</span>
      <span class="post-categories">
      <!-- <i class="fas fa-tag"></i> -->
      <!-- <i class="far fa-book"></i> -->
      <i class="fas fa-box"></i>
      
      
        <a target="_blank" href="/blog/category/#Machine Learning">Machine Learning</a>
        
      
    </span>

    </div>
    <!-- <h2 id="boosting">Boosting</h2>

<p><img src="http://localhost:4000/blog/img/posts/boosting.png" alt="boosting.png" height="230px" width="600px" /></p>

<p>From: <a href="https://blog.bigml.com/2017/03/14/introduction-to-boosted-trees/">Introduction to Boosted Trees</a></p>

<p>Boosting 也是一種 Ensemble learning，它會結合多個弱分類器（weak classifiers）成為一個較準確的分類器，也可以應用在 regression 上。</p>

<hr />

<p><strong>和 Bagging 有什麼不同？</strong></p>

<p>Bagging 各個 classifier 產生的過程是獨立的，但 Boosting 後產生的 classifier 與前面的 classifier 有關。也就是說，Bagging 的 classifier 可以並行產生，但 Boosting 必須要有順序的產生。所以時間上來說，Bagging 可以節省比較多的時間。</p>

<hr />

<p><strong>與前面的分類器有關？</strong></p>

<p>在 Boosting 中，每一次產生 classifier 後，後面的 classifier 會根據前面 classifier 的結果調整每個點的權重。</p>

<p>在前一個 classifier 分類錯誤後，在後一個 classifier 的權重會比較重，而表現較好的則會權重減少。這就是和 Bagging 最大的不同，Bagging 中所有的點都是隨機選取，且權重都是一樣的。</p>

<p>簡單來說，Boosting learns features from data.</p>

<hr />

<p><strong>步驟</strong></p>

<ol>
  <li>用最原始的 training data 跑一個 classifiers</li>
  <li>利用這個 classifiers 提高分類錯誤的點的權重，降低分類正確的點的權重。</li>
  <li>重複第二步驟 N 次，最後使用權重的平均值。</li>
</ol>

<hr />

<h2 id="adaboost">AdaBoost</h2>

<p><img src="http://localhost:4000/blog/img/posts/AdaBoost.png" alt="AdaBoost.png" height="350px" width="700px" /></p>

<p>From: <a href="https://medium.com/@chih.sheng.huang821/機器學習-ensemble-learning之bagging-boosting和adaboost-af031229ebc3">機器學習: Ensemble learning之Bagging、Boosting和AdaBoost</a></p>

<p>AdaBoost 應用了 boosting 的方法。</p>

<p><strong>概念</strong></p>

<p>假設現在有 n 個樣本，要執行 boosting T 次。</p>

<p>第一次將所有樣本的權重都設為 \(\alpha_i\) = 1/n, i = 1, …, n</p>

<p>對所有 t = 1, …, T</p>
<ol>
  <li>根據樣本的權重 \(\alpha_i\) 建立出 classifier \(f_t(x)\)</li>
  <li>使用 \(f_t(x)\) 後計算 \(\epsilon_t\) 誤差</li>
  <li>利用 \(\epsilon_t\) 算出係數 \(w_t\)</li>
  <li>再重新計算 \(\alpha_i\)</li>
</ol>

<p>最後的 model 就會是：</p>

<p>\(\hat{y} = sign \sum_{t=1}^{T} w_i f_t(x)\)</p>

<p>AdaBoost 的優勢就是讓 model 能夠從錯中學，使用提升與降低權重的方式讓分類錯誤的點可以在下一次的 model 中被改進。</p>

<hr />

<p>Reference:
<br />
<a href="http://leijun00.github.io/2014/10/decision-tree-2/">决策树（二）</a>
<br />
<a href="https://medium.com/@chih.sheng.huang821/機器學習-ensemble-learning之bagging-boosting和adaboost-af031229ebc3">機器學習: Ensemble learning之Bagging、Boosting和AdaBoost</a>
<br />
<a href="https://blog.csdn.net/niuniuyuh/article/details/54346930">AdaBoost和随机森林的区别</a>
<br />
<a href="https://www.coursera.org/learn/ml-classification/home/week/5">Machine Learning -  University of Washington</a>
<br />
<a href="https://blog.csdn.net/mach_learn/article/details/39501849">机器学习算法优缺点及其应用领域</a></p>
 -->
    <div class="post-excerpt"><h2 id="boosting">Boosting</h2>

</div>

    <div class="bookmark">
      <!-- <i class="far fa-comments"></i> -->
      <i class="fas fa-comments"></i>
      <span>
        


<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
var disqus_config = function () {
        // this.page.url = '/blog//machine%20learning/2018/12/03/Machine-Learning-Boosting-and-Adaboost/#disqus_thread';
        this.page.identifier = '/machine%20learning/2018/12/03/Machine-Learning-Boosting-and-Adaboost/';
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://mcshihs.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>



        <a href="/blog//machine%20learning/2018/12/03/Machine-Learning-Boosting-and-Adaboost/#disqus_thread" data-disqus-identifier="/machine%20learning/2018/12/03/Machine-Learning-Boosting-and-Adaboost/">0 Comments</a>
      </span>

    </div>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/blog/machine%20learning/2018/12/03/Machine-LearningDecision-Tree/">
        [Machine Learning]Random Forest
      </a>
    </h1>

    <div class="post-info">
      <!-- <span class="post-date">Posted by Shihs on December 3, 2018</span> -->
      <i class="fas fa-calendar-alt"></i>
      <span class="post-date">December 3, 2018</span>
      <span class="post-categories">
      <!-- <i class="fas fa-tag"></i> -->
      <!-- <i class="far fa-book"></i> -->
      <i class="fas fa-box"></i>
      
      
        <a target="_blank" href="/blog/category/#Machine Learning">Machine Learning</a>
        
      
    </span>

    </div>
    <!-- <p>基本上 Random Frost 是要改善 Decision Tree 容易 overfitting 的問題，它結合了 Decision Tree 和 bagging 的方法。</p>

<p>Random Forest 是建立很多顆決策樹，再利用多數決選出最好的選項，和 <a href="https://shihs.github.io/blog/machine%20learning/2018/12/03/Machine-Learning-Bagging/">bagging</a> 這篇提到的方法有點類似，但有些小差異。</p>

<p>使用的方法是 bagging（結合多個 model），所以這也是 Ensemble learning。</p>

<hr />

<p><strong>Random Forest步驟</strong></p>

<p>假如有一 training data，有 N 個樣本，p 個features。
<br />
今天要利用這個 training data 建立一個 Random Forest model，裡頭共有 B 棵決策樹，</p>

<ol>
  <li>使用 boostrap 從 training data 中抽出 N 個樣本產生一組 data</li>
  <li>在這組 data 中隨機從 p 個 featrues 中選取 m (m &lt; p) 個 features，再從這 m 個 features 找出最好的一個分割結果，如此產生一個 node</li>
  <li>重複步驟 2，直到完成這個 model 為止</li>
  <li>重複步驟 1~3 B 次，共會產生 B 棵擁有不同 feature 的決策樹</li>
</ol>

<p>最後要進行 predict 時，分類問題使用多數決，回歸問題使用平均數決定。</p>

<hr />

<ul>
  <li>因為每一棵樹的隨機選取的樣本與 feature 都不同，所以每棵樹的結果都不會相同。</li>
  <li>Random Frost 建立的 decision tree 不需要 pruning。在 decision tree 剪枝是爲了避免 overfitting，但在 Random Frost 使用 bagging 的方式就已經避免 overfitting 了。</li>
  <li>因為每一棵決策樹都是隨機篩選 feature 的結果，所以可以想像每棵樹就像是精通某個領域的專家。當有個新的數據近來，經由各個領域的專家投票表決，做出最後的選擇。</li>
  <li>
    <p>Random Forest 中有兩個參數需要人為控制，一個是樹的數量（B），一般建議取很大。另一個是 feature 的大小（m）。</p>
  </li>
  <li>優點：
    <ol>
      <li>不用做特徵（feature）選擇。</li>
      <li>訓練完後可以知道哪些 feature 比較重要。</li>
    </ol>
  </li>
</ul>

<hr />

<p>Reference:
<br />
<a href="https://www.youtube.com/watch?v=J4Wdy0Wc_xQ">StatQuest: Random Forests Part 1 - Building, Using and Evaluating</a>
<br />
<a href="https://blog.csdn.net/edogawachia/article/details/79357844">随机森林（Random Forest）算法原理</a>
<br />
<a href="https://blog.csdn.net/niuniuyuh/article/details/54346930">AdaBoost和随机森林的区别</a></p>
 -->
    <div class="post-excerpt"><p>基本上 Random Frost 是要改善 Decision Tree 容易 overfitting 的問題，它結合了 Decision Tree 和 bagging 的方法。</p>

</div>

    <div class="bookmark">
      <!-- <i class="far fa-comments"></i> -->
      <i class="fas fa-comments"></i>
      <span>
        


<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
var disqus_config = function () {
        // this.page.url = '/blog//machine%20learning/2018/12/03/Machine-LearningDecision-Tree/#disqus_thread';
        this.page.identifier = '/machine%20learning/2018/12/03/Machine-LearningDecision-Tree/';
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://mcshihs.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>



        <a href="/blog//machine%20learning/2018/12/03/Machine-LearningDecision-Tree/#disqus_thread" data-disqus-identifier="/machine%20learning/2018/12/03/Machine-LearningDecision-Tree/">0 Comments</a>
      </span>

    </div>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/blog/machine%20learning/2018/12/03/Machine-Learning-Bagging/">
        [Machine Learning]Bagging
      </a>
    </h1>

    <div class="post-info">
      <!-- <span class="post-date">Posted by Shihs on December 3, 2018</span> -->
      <i class="fas fa-calendar-alt"></i>
      <span class="post-date">December 3, 2018</span>
      <span class="post-categories">
      <!-- <i class="fas fa-tag"></i> -->
      <!-- <i class="far fa-book"></i> -->
      <i class="fas fa-box"></i>
      
      
        <a target="_blank" href="/blog/category/#Machine Learning">Machine Learning</a>
        
      
    </span>

    </div>
    <!-- <h2 id="bagging">Bagging</h2>

<p><img src="http://localhost:4000/blog/img/posts/bagging.png" alt="bagging.png" height="450px" width="500px" /></p>

<p>From: Hastie, T., Tibshirani, R. and Friedman, J. The Elements of Statistical Learning. Springer, 2009. p.285</p>

<hr />

<p><strong>Bagging 是什麼？</strong></p>

<p>Bootstrap aggregating (bagging) is a machine learning ensemble meta-algorithm to improve classification and regression models in terms of stability and classification accuracy. It also reduces variance and helps to avoid ‘overfitting’. Although it is usually applied to decision tree models, it can be used with any type of model. (<a href="https://docs.rapidminer.com/latest/studio/operators/modeling/predictive/trees/parallel_decision_tree.html">Decision Tree - Bagging</a>)</p>

<p>簡單來說，Bagging是一種 Ensemble learning方法，它集結一些 model 來做最後的決策。通常會是集結表現沒那麼好的 model，讓這些 model 一起做決定，一種三個臭皮匠勝過一個諸葛亮的感覺。</p>

<p>Decision tree 是一個常見的 weak classifier，所以如果在 decision tree 上使用 bagging，可以讓最後表現結果比較好，也避免 overfitting 的情況。</p>

<hr />

<p><strong>Boostrap</strong></p>

<p>在開始說明 bagging 步驟前先介紹 bootstrap。</p>

<p>bootstrap 是一種抽樣方法。假設今天有一組資料，裡頭共有 N 個樣本，我們想要有 m 個大小為 N 的樣本作為訓練資料。方法是，每次從這 N 個樣本隨機抽取，且每次都是取後放回(也就是有些樣本可能被抽到一次以上，有些樣本可能沒被抽到)，同樣的方法重複 m 次，這樣我們就會有 m 組樣本數為 N 的 y 資料集。</p>

<p>這樣的方法在樣本數量少時很有用。如果樣本小，但我們用 train-validation-test 這樣的方式訓練資料，訓練的樣本資料非常小，會造成 bias 較大的問題。而使用 bootstrap 不會減少樣本的數量，也能保留 test data。</p>

<hr />

<p><strong>如何操作？</strong></p>

<ol>
  <li>使用 boostrap 方法從 training data 中採集 B 組樣本數與 training data 相同的資料集。</li>
  <li>這 B 組資料集都建立一個 model， \(f_b(x)\)，共產生 B 個 model。</li>
  <li>最後預測的結果就是將這 B 個 model 做統合。在分類問題上，可以平均各個 model 的 posterior class probabilities，或是使用 majority voting。（選機率比較大的結果或是多數決）；在回歸上，則取平均值。</li>
</ol>

<p>從最上圖可以看到，不論是使用機率或是投票決定，bagging 選出的結果的 test error 都要比個別的 model 表現較好。</p>

<hr />

<p>除了 Bagging 外，Ensemble learning 還有另一種常見的方法 Boosting，這篇先到這裡之後繼續介紹。</p>

<hr />

<p>Reference:
<br />
<a href="https://medium.com/@chih.sheng.huang821/機器學習-ensemble-learning之bagging-boosting和adaboost-af031229ebc3">機器學習: Ensemble learning之Bagging、Boosting和AdaBoost</a>
<br />
<a href="https://blog.csdn.net/edogawachia/article/details/79357844">随机森林（Random Forest）算法原理</a>
<br />
The Elements of Statistical Learning
<br />
Pattern Recognition and Machine Learning</p>

 -->
    <div class="post-excerpt"><h2 id="bagging">Bagging</h2>

</div>

    <div class="bookmark">
      <!-- <i class="far fa-comments"></i> -->
      <i class="fas fa-comments"></i>
      <span>
        


<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
var disqus_config = function () {
        // this.page.url = '/blog//machine%20learning/2018/12/03/Machine-Learning-Bagging/#disqus_thread';
        this.page.identifier = '/machine%20learning/2018/12/03/Machine-Learning-Bagging/';
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://mcshihs.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>



        <a href="/blog//machine%20learning/2018/12/03/Machine-Learning-Bagging/#disqus_thread" data-disqus-identifier="/machine%20learning/2018/12/03/Machine-Learning-Bagging/">0 Comments</a>
      </span>

    </div>
    
  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/blog/page6">Older</a>
  
  
    
      <a class="pagination-item newer" href="/blog/page4">Newer</a>
    
  
</div>

    </div>
    <script id="dsq-count-scr" src="//mcshihs.disqus.com/count.js" async></script>
  </body>
</html>
