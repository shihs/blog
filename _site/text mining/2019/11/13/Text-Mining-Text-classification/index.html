<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>M.C. Shih &middot; BLOG</title>  
  

  <!-- CSS -->
  <link rel="stylesheet" href="/blog/public/css/poole.css">
  <link rel="stylesheet" href="/blog/public/css/syntax.css">
  <link rel="stylesheet" href="/blog/public/css/hyde.css">
  <link rel="stylesheet" href="/blog/public/css/custom.css">
  <link rel="stylesheet" href="/blog/public/css/fontawesome-all.css">
  <link rel="stylesheet" href="/blog/public/css/fontawesome-all.min.css">
  <!-- <link href="https://use.fontawesome.com/releases/v5.0.8/css/all.css" rel="stylesheet"> -->


  <!--<link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface"> -->

  <!-- Icons -->
  <link rel="apple-touch-icon" sizes="16x16" href="/blog/public/apple-touch-icon-16-precomposed.png">
  <link rel="apple-touch-icon" sizes="24x24" href="/blog/public/apple-touch-icon-24-precomposed.png">
  <link rel="apple-touch-icon" sizes="32x32" href="/blog/public/apple-touch-icon-32-precomposed.png">
  <link rel="apple-touch-icon" sizes="48x48" href="/blog/public/apple-touch-icon-48-precomposed.png">
  <link rel="apple-touch-icon" sizes="57x57" href="/blog/public/apple-touch-icon-57-precomposed.png">
  <link rel="apple-touch-icon" sizes="64x64" href="/blog/public/apple-touch-icon-64-precomposed.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/blog/public/apple-touch-icon-72-precomposed.png"> 
  <link rel="apple-touch-icon" sizes="114x114" href="/blog/public/apple-touch-icon-114-precomposed.png"> 
  <link rel="apple-touch-icon" sizes="120x120" href="/blog/public/apple-touch-icon-120-precomposed.png"> 
  <link rel="apple-touch-icon" sizes="144x144" href="/blog/public/apple-touch-icon-144-precomposed.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/blog/public/apple-touch-icon-152-precomposed.png">
  <link rel="apple-touch-icon" sizes="512x512" href="/blog/public/apple-touch-icon-512-precomposed.png">
  <link rel="shortcut icon" href="/blog/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/blogblog/atom.xml">
  <!-- 數學符號 -->
  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
</head>


  <body>
  	
    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/blog/">
          M.C. Shih
        </a>
        <img src="/blog/img/headshot.png" alt="Author Image" class="headshot">
      </h1>
      <p class="lead">Just for learning.</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/blog/">Blog</a>

      

      
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/blog/about/">About</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="/blog/archive/">Archives</a>
          
        
      
        
      
        
          
            <a class="sidebar-nav-item" href="/blog/category/">Category</a>
          
        
      
        
          
        
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/blog/search/">Search</a>
          
        
      
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      

    </nav>
    <div class="links">
      <ul>
        <li><a href="https://shihs.github.io" class="homepage" target="_blank"><img src="/blog/img/link%20icon/iconmonstr-home-6-240.png"></a></li>
        <li><a href="https://github.com/shihs" class="github" target="_blank"><img src="/blog/img/link%20icon/iconmonstr-github-3-240.png"></a></li>
        <li><a href="https://www.linkedin.com/in/min-chun-shih-6647779a/" class="linkedin" target="_blank"><img src="/blog/img/link%20icon/iconmonstr-linkedin-3-240.png"></a></li>
        <li><a href="https://www.instagram.com/itakephotos_tw/" class="instagram" target="_blank"><img src="/blog/img/link%20icon/iconmonstr-instagram-8-240.png"></a></li>
        <li><a href="https://www.flickr.com/photos/mcshihs/" class="flickr" target="_blank"><img src="/blog/img/link%20icon/iconmonstr-flickr-3-240.png"></a></li>
      </ul>
    </div>
    

    <p class = "rights">&copy; 2022. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="post">
  <h1 class="post-title">[Text Mining]Text classification</h1>
  <div class="post-info">
    <i class="fas fa-calendar-alt"></i>
    <span class="post-date">November 13, 2019</span>
    <span>
      <i class="fas fa-comments"></i>
      <a
        class="comment-count"
        href="/blog//text%20mining/2019/11/13/Text-Mining-Text-classification/#disqus_thread"
        data-disqus-identifier="/text%20mining/2019/11/13/Text-Mining-Text-classification/"
        >0 Comments</a
      >
    </span>
    <span class="post-categories">
      <!-- <i class="fas fa-tag"></i> -->
      <!-- <i class="far fa-book"></i> -->
      <i class="fas fa-box"></i>
       
      <a
        target="_blank"
        href="/blog/category/#Text Mining"
        >Text Mining</a
      >
       
    </span>
  </div>
  <div><p>This post is based on the <a href="https://www.ida.liu.se/~732A92/index.en.shtml">732A92 Texting Mining</a> course, given by Marco Kuhlmann at LiU in 2019.</p>

<hr />

<h2 id="text-classification">Text classification</h2>

<ul>
  <li>Text classification is the task of categorising text documents into predefined classes.</li>
</ul>

<h2 id="evaluation-of-text-classifiers">Evaluation of text classifiers</h2>

<p>最簡單的檢視預測結果好壞的方法就是將 predict 出來的類別與真實的類別做比較。（預測必須要在 test data，換句話說之前並沒有參與任何 training 的過程。這點在做所有 Machine Learning 的方法都很重要，在做 model 測試前不要碰 test data。）</p>

<h3 id="accuracy">Accuracy</h3>
<p>The accuracy of a classifier is the proportion of documents for which the classifier predicts the gold-standard class:</p>

<script type="math/tex; mode=display">\textrm{accuarcy} = \frac{\textrm{number of correctly classified documents}}{\textrm{number of all documents}}</script>

<h3 id="accuracy-and-imbalanced-data-sets">Accuracy and imbalanced data sets</h3>

<p>上面的 accuracy 看起來非常合理啊，去計算分類正確的比例來判斷這個分類器是否預測準確。但，如果其實資料本身的類別並不平均呢？</p>

<p><img src="http://localhost:4000/blog/img/posts/imbalanced%20data%20sets.png" alt="PMF_two coins.png" /></p>

<p>根據上圖，我們只要把所有資料都猜綠色的 class，這樣 accuracy 就能有 80%。從這個例子可以知道，</p>

<ul>
  <li>
    <p>Evaluation measures are no absolute measures of performance. 如果今天得到 accuracy 是 80% 我們並無法確定這樣的準確率的好壞，要根據每個問題去判斷。</p>
  </li>
  <li>
    <p>Instead, we should ask for a classifier’s performance relative to other classifiers, or other points of comparison. E.g.’Logistic Regression has a higher accuracy than Naive Bayes.’</p>
  </li>
  <li>
    <p>When other classifiers are not available, a simple baseline is to always predict the most frequent class in the training data.</p>
  </li>
</ul>

<h2 id="precision-and-recall">Precision and recall</h2>

<ul>
  <li>
    <p>Precision and recall ‘zoom in’ on how good a system is at identifying documents of a specific class.</p>
  </li>
  <li>
    <p>Precision is the proportion of correctly classified documents among all documents for which the system predicts class.</p>
  </li>
</ul>

<script type="math/tex; mode=display">\textrm{precision} = \frac{\textrm{# true positives}}{\textrm{# true positives + # false positives}}</script>

<ul>
  <li>Recall is the proportion of correctly classified documents among all documents with gold-standard class.</li>
</ul>

<script type="math/tex; mode=display">\textrm{recall} = \frac{\textrm{# true positives}}{\textrm{# true positives + # false negatives}}</script>

<h2 id="f1-measure">F1-measure</h2>
<p>A good classifier should balance between precision and recall.  </p>

<script type="math/tex; mode=display">\textrm{F1} = \frac{2 \cdot \textrm{precision} \cdot \textrm{recall}}{\textrm{precision + recall}}</script>

<hr />

<h2 id="naive-bayes-classifier">Naive Bayes classifier</h2>

<h3 id="bayes-theorem">Bayes’ theorem</h3>

<p>We know that <script type="math/tex">C</script> is classes, <script type="math/tex">x_i, i = 1, \cdots,n</script> is features. Using Bayes’ theorem, the conditional probability can be decomposed as</p>

<script type="math/tex; mode=display">p(C|x_1,..., x_n) = \frac{p(C)~p(x_1, \cdots,x_n|C)}{p(x_1, \cdots,x_n)}</script>

<p>也就是，</p>

<script type="math/tex; mode=display">\textrm{posterior} = \frac{\textrm{prior} \times \textrm{likelihood}}{\textrm{evidence}}</script>

<p>根據上式，我們可以將分母視為常數，因為 features <script type="math/tex">x_i, i = 1, \cdots,n</script> 的值是給定的，且與 <script type="math/tex">C</script> 無關，所以可以得到</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
p(C, x_1, \cdots,x_n) & = p(C)~p(x_1,\cdots,x_n|C) \\
& \propto p(C)~p(x_1|C)~p(x_2,\cdots,x_n|C,x_1) \\
& \propto p(C)~p(x_1|C)~p(x_2|C, x_1)~p(x_3,\cdots,x_n|C,x_1,x_2) \\ 
& \propto p(C)~p(x_1|C)~p(x_2|C, x_1)~p(x_3|C, x_1, x_2)~p(x_4,\cdots,x_n|C,x_1,x_2,x_3) \\
& \propto \cdots\\
& \propto p(C)~p(x_1|C)~p(x_2|C, x_1)~p(x_3|C, x_1, x_2) \cdots p(x_n|C,x_1,x_2,\cdots ,x_n) \\
\end{align} %]]></script>

<h3 id="naive-bayes-assumption">Naive Bayes assumption</h3>

<p>Naive Bayes 假設 
<script type="math/tex">p(x_i|C, x_j) = p(x_i|C), \textrm{for} ~ i \ne j</script></p>

<p>根據 Naive Bayes 的假設，前面的式子我們可以寫成，</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
p(C|x_1,..., x_n) & \propto p(C, x_1, \cdots,x_n) \\
& \propto p(C)~p(x_1|C)~p(x_2|C)~p(x_3|C) \cdots p(x_n|C) \\
& \propto p(C)~\prod_{i=1}^n p(x_i|C)
\end{align} %]]></script>

<p>根據上面的推導過程，我們可以得到，</p>

<script type="math/tex; mode=display">p(C|x_1,..., x_n) = \frac{1}{Z}~p(C)~\prod_{i=1}^n p(x_i|C)</script>

<h3 id="naive-bayes-classifer">Naive Bayes classifer</h3>

<p>而 Naive Bayes classifer 就是取各個分類 <script type="math/tex">C_m, m = 1, \cdots, k</script> 
中 <script type="math/tex">p(C|x_1,..., x_n)</script> 值最大的為最後的分類結果。換句話說，我們可用這樣的式子表示</p>

<script type="math/tex; mode=display">C_m = \mathop{\arg\max}_C p(C|x_1,..., x_n) =  \mathop{\arg\max}_C p(C)~\prod_{i=1}^n p(x_i|C)</script>

<p>而 <script type="math/tex">C_m</script> 就是最後的分類結果。</p>

<h3 id="two-classic-naive-bayes-variants-for-text">Two Classic Naive Bayes Variants for Text</h3>

<ol>
  <li>Multinomial Naive Bayes
    <ul>
      <li>Data follows a multinomial distribution (多項分布)</li>
      <li>Each feature values is a count (word occurrence counts, TF-IDF weighting, …)</li>
    </ul>
  </li>
  <li>Bernoulli Naive Bayes
    <ul>
      <li>Data follows a multivariate Bernoulli distribution</li>
      <li>Each feature is binary (word is present / absent)</li>
    </ul>
  </li>
</ol>

<hr />

<p><strong>Lab:</strong> <a href="https://github.com/shihs/732A92-TextMining/blob/master/Lab1/TM-L2.ipynb">Text classification Lab</a></p>

<hr />

<p><strong>Reference:</strong>
<br />
<a href="https://www.ida.liu.se/~732A92/index.en.shtml">732A92 Texting Mining</a>
<br />
<a href="https://www.ycc.idv.tw/confusion-matrix.html">如何辨別機器學習模型的好壞？秒懂Confusion Matrix</a>
<br />
<a href="https://zh.wikipedia.org/wiki/朴素贝叶斯分类器">wikipeida - 單純貝氏分類器</a></p>

</div>
</div>

<div class="likecoin">
  
  <iframe
    src="https://button.like.co/in/embed/shihs_tw/button?referrer=http%3A%2F%2Flocalhost%3A4000%2Fblog%2Ftext%2520mining%2F2019%2F11%2F13%2FText-Mining-Text-classification%2F" height="200" width="560" allowfullscreen="" frameborder="0"
  >
  </iframe>
  
</div>

  
<a name="comments"></a>
<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
var disqus_config = function () {
        // this.page.url = '/blog/#disqus_thread';
        this.page.identifier = '/text%20mining/2019/11/13/Text-Mining-Text-classification/';
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://mcshihs.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>



  <div class="related">
    <h2>Latest Posts</h2>
    <ul class="related-posts">
      
      <li>
        <h3>
          <a href="/blog/2022/04/05/Test/"> Test </a>
          <small>Apr 5, 2022</small>
        </h3>
      </li>
      
      <li>
        <h3>
          <a href="/blog/python/2022/04/05/Python-%E5%9C%A8-Mac-%E4%B8%8B%E8%BC%89%E8%88%87%E5%AE%89%E8%A3%9D-Miniconda/"> [Python]在 Mac 下載與安裝 Miniconda </a>
          <small>Apr 5, 2022</small>
        </h3>
      </li>
      
      <li>
        <h3>
          <a href="/blog/python/2022/04/05/Python-%E8%99%9B%E6%93%AC%E7%92%B0%E5%A2%83-(virtual-environment)-conda-create-%E8%88%87-virtualenv-%E6%AF%94%E8%BC%83/"> [Python]Python 虛擬環境 (virtual environment) - conda create 與 virtualenv 比較 </a>
          <small>Apr 5, 2022</small>
        </h3>
      </li>
      
    </ul>
  </div>
</div>

    </div>
    <script id="dsq-count-scr" src="//mcshihs.disqus.com/count.js" async></script>
  </body>
</html>
