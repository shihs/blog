<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>M.C. Shih &middot; BLOG</title>  
  

  <!-- CSS -->
  <link rel="stylesheet" href="/blog/public/css/poole.css">
  <link rel="stylesheet" href="/blog/public/css/syntax.css">
  <link rel="stylesheet" href="/blog/public/css/hyde.css">
  <link rel="stylesheet" href="/blog/public/css/custom.css">
  <link rel="stylesheet" href="/blog/public/css/fontawesome-all.css">
  <link rel="stylesheet" href="/blog/public/css/fontawesome-all.min.css">
  <!-- <link href="https://use.fontawesome.com/releases/v5.0.8/css/all.css" rel="stylesheet"> -->


  <!--<link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface"> -->

  <!-- Icons -->
  <link rel="apple-touch-icon" sizes="16x16" href="/blog/public/apple-touch-icon-16-precomposed.png">
  <link rel="apple-touch-icon" sizes="24x24" href="/blog/public/apple-touch-icon-24-precomposed.png">
  <link rel="apple-touch-icon" sizes="32x32" href="/blog/public/apple-touch-icon-32-precomposed.png">
  <link rel="apple-touch-icon" sizes="48x48" href="/blog/public/apple-touch-icon-48-precomposed.png">
  <link rel="apple-touch-icon" sizes="57x57" href="/blog/public/apple-touch-icon-57-precomposed.png">
  <link rel="apple-touch-icon" sizes="64x64" href="/blog/public/apple-touch-icon-64-precomposed.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/blog/public/apple-touch-icon-72-precomposed.png"> 
  <link rel="apple-touch-icon" sizes="114x114" href="/blog/public/apple-touch-icon-114-precomposed.png"> 
  <link rel="apple-touch-icon" sizes="120x120" href="/blog/public/apple-touch-icon-120-precomposed.png"> 
  <link rel="apple-touch-icon" sizes="144x144" href="/blog/public/apple-touch-icon-144-precomposed.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/blog/public/apple-touch-icon-152-precomposed.png">
  <link rel="apple-touch-icon" sizes="512x512" href="/blog/public/apple-touch-icon-512-precomposed.png">
  <link rel="shortcut icon" href="/blog/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/blog/blog/atom.xml">
  <!-- 數學符號 -->
  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
</head>


  <body>
  	
    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/blog/">
          M.C. Shih
        </a>
        <img src="/blog/img/headshot.png" alt="Author Image" class="headshot">
      </h1>
      <p class="lead">Just for learning.</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/blog/">Blog</a>

      

      
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/blog/about">About</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="/blog/archive">Archives</a>
          
        
      
        
      
        
          
            <a class="sidebar-nav-item" href="/blog/category">Category</a>
          
        
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/blog/search">Search</a>
          
        
      
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      

    </nav>
    <div class="links">
      <ul>
        <li><a href="https://shihs.github.io" class="homepage" target="_blank"><img src="/blog/img/link%20icon/iconmonstr-home-6-240.png"></a></li>
        <li><a href="https://github.com/shihs" class="github" target="_blank"><img src="/blog/img/link%20icon/iconmonstr-github-3-240.png"></a></li>
        <li><a href="https://www.linkedin.com/in/min-chun-shih-6647779a/" class="linkedin" target="_blank"><img src="/blog/img/link%20icon/iconmonstr-linkedin-3-240.png"></a></li>
        <li><a href="https://www.instagram.com/itakephotos_tw/" class="instagram" target="_blank"><img src="/blog/img/link%20icon/iconmonstr-instagram-8-240.png"></a></li>
        <li><a href="https://www.flickr.com/photos/mcshihs/" class="flickr" target="_blank"><img src="/blog/img/link%20icon/iconmonstr-flickr-3-240.png"></a></li>
      </ul>
    </div>
    

    <p class = "rights">&copy; 2023. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="post">
  <h1 class="post-title">[Text Mining]Text clustering and topic modelling</h1>
  <div class="post-info">
    <i class="fas fa-calendar-alt"></i>
    <span class="post-date">November 21, 2019</span>
    <span>
      <i class="fas fa-comments"></i>
      <a
        class="comment-count"
        href="/blog///2019/11/Text-Mining-Text-clustering-and-topic-modelling.html#disqus_thread"
        data-disqus-identifier="/2019/11/Text-Mining-Text-clustering-and-topic-modelling.html"
        >0 Comments</a
      >
    </span>
    <span class="post-categories">
      <!-- <i class="fas fa-tag"></i> -->
      <!-- <i class="far fa-book"></i> -->
      <i class="fas fa-box"></i>
       
      <a
        target="_blank"
        href="/blog//category/#Text Mining"
        >Text Mining</a
      >
       
    </span>
  </div>
  <div><p>This post is based on the <a href="https://www.ida.liu.se/~732A92/index.en.shtml">732A92 Texting Mining</a> course, given by Marco Kuhlmann at LiU in 2019.</p>

<hr />

<p>在進入 Text clustering 前我想要先介紹 <strong>Clustering</strong>。</p>

<h2 id="clustring">Clustring</h2>

<ul>
  <li>
    <p>Clustering (分群）是一種 unsupervised learning（非監督學習）</p>
  </li>
  <li>Typical applications
    <ol>
      <li>As a stand-alone tool to get insight into data distribution</li>
      <li>As a preprocessing step for other algorithms</li>
    </ol>
  </li>
  <li>Cluster: a collection of data objects。但什麼樣的 data 會被歸在同一個 cluster 呢？ 這就是 clustering 最重要的概念，<strong>Similar</strong> 和 <strong>Dissimilar</strong>。</li>
  <li><strong>Similar</strong> to one another within the same cluster</li>
  <li><strong>Dissimilar</strong> to the objects in other clusters</li>
</ul>

<p>=&gt; 而提到 Similar 和 Dissimilar 就要必須要提到 distance (or similarity) measures。有了 distance（similarity）才有辦法定義 Similar 和 Dissimilar。</p>

<h3 id="distancesimilarity">Distance（Similarity）</h3>

<ul>
  <li>Distances are normally used to measure the similarity or dissimilarity between two data objects</li>
</ul>

<p>Distances 可以有很多種定義方式，但不管怎麼定義，都一定要符合以下的 properties。</p>
<ul>
  <li>\(d(i, j) \ge 0\) (non-negativity)</li>
  <li>\(d(i, i) = 0\) (identity of indiscernibles)</li>
  <li>\(d(i, j) = d(j, i)\) (symmetry)</li>
  <li>\(d(i, j) \le d(i, k) + d(k, j)\) (triangle inequality)</li>
</ul>

<p><strong>Minkowski distance</strong></p>

<p>\(d(i, j) = \sqrt[q]{(|x_{i_1} - x_{j_1}|^q + |x_{i_2} - x_{j2}|^q + \ldots + |x_{i_p} - x_{j_p}|^q)}\)
, q is a positive integer</p>

<ul>
  <li>If q = 1, d is Manhattan distance</li>
  <li>If q = 2, d is Euclidean distance</li>
</ul>

<p><strong>Binary Variables</strong></p>

<ul>
  <li>symmetric binary variables: both states are equally important; 0/1</li>
  <li>asymmetric binary variables: one state is more important than the other (e.g. outcome of disease test); 1 is the important state, 0 the other</li>
</ul>

<p><img src="http://localhost:4000/blog/img/posts/Contingency%20tables%20for%20Binary%20Variables.png" alt="PMF_two coins.png" /></p>

<ul>
  <li>Accuracy for symmetric binary variables</li>
</ul>

\[sim(i, j) = \frac{a+d}{a+b+c+d}\]

<ul>
  <li>Jaccard similarity for asymmetric binary variables</li>
</ul>

\[sim(i, j) = \frac{a}{a+b+c}\]

<hr />

<h2 id="text-clustering">Text clustering</h2>

<p><img src="http://localhost:4000/blog/img/posts/Conceptual%20framework%20for%20text%20mining.png" alt="PMF_two coins.png" /></p>

<p>上圖是 Conceptual framework for text mining，而這篇要介紹的是 Clustering 和 Topic Analysis。</p>

<ul>
  <li>
    <p><strong>Text clustering</strong> is the task of grouping similar texts together. What is considered ‘similar’ depends on the application.</p>
  </li>
  <li>
    <p>Clustering is a central tool in exploratory data analysis, where it can help us to get insights into the distribution of a data set.</p>
  </li>
  <li>
    <p>Clustering is also useful as a pre-processing technique in knowledge-focused applications. Example: Brown clustering</p>
  </li>
</ul>

<p><img src="http://localhost:4000/blog/img/posts/The%20standard%20text%20clustering%20pipeline.png" alt="PMF_two coins.png" /></p>

<hr />

<h2 id="similarity-measures">Similarity measures</h2>

<p>剛剛前面提到的 Similarity，如何用在 text 上呢？</p>

<p><strong>Accuracy for symmetric binary vectors</strong></p>

<p><img src="http://localhost:4000/blog/img/posts/Accuracy%20for%20symmetric%20binary%20vectors.png" alt="PMF_two coins.png" /></p>

<p><strong>Jaccard similarity for asymmetric binary vectors</strong></p>

<hr />

<h2 id="hard-clustering-and-soft-clustering">Hard clustering and soft clustering</h2>

<p><strong>Hard clustering</strong></p>
<ul>
  <li>Each document either belongs to a cluster or not. Ex. Hierarchical clustering(brown clustring), Partitioning clustering(k-means), Density-Based clustering(DBSCAN)</li>
</ul>

<p><strong>Soft clustering</strong></p>
<ul>
  <li>Each document belongs to each cluster to a certain degree. Ex. LDA (topic model)</li>
</ul>

<hr />

<h2 id="an-overview-of-hard-clustering-methods">An overview of hard clustering methods</h2>

<h3 id="hierarchical-clustering">Hierarchical clustering</h3>

<p>This method does not require the number of clusters k as an input, but needs a termination condition</p>

<p><img src="http://localhost:4000/blog/img/posts/Hierarchical%20Clustering.png" alt="" /></p>

<ul>
  <li>
    <p><strong>Agglomerative</strong>: Each document starts in its own cluster. Hierarchy is created by merging pairs of clusters.
將點倆倆合併，最後所有的點會全部在同一個 cluster 裡。那至於要用什麼決定要將兩個點合併呢？這時候又有 Linkage criteria 來決定，eg. Single-link, Complete-link, Average-link 等等。不同的 linkage criteria 會導致不同的分群結果，如下圖。</p>
  </li>
  <li>
    <p><strong>Divisive clustering</strong>: All documents start in one cluster. Hierarchy is created by splitting clusters recursively.</p>
  </li>
</ul>

<p><img src="http://localhost:4000/blog/img/posts/Linkage%20criteria.png" alt="" /></p>

<ul>
  <li><strong>Brown clustring</strong></li>
</ul>

<h3 id="partitioning-clustering">Partitioning clustering</h3>
<ul>
  <li>
    <p><strong>K-means</strong></p>
  </li>
  <li>
    <p>Issues with the k-means algorithm</p>
    <ol>
      <li>The k-means algorithm always converges, but there is no guarantee that it finds a global optimum. (Solution: random restarts)</li>
      <li>The number of clusters needs to be specified in advance, or chosen based on heuristics and cross-validation. (Example: elbow method)</li>
      <li>The k-means algorithm is not good at handling outliers – every document will eventually belong to some cluster.</li>
      <li>K-means is restricted to clusters with convex shapes =&gt; Density-Based clustering</li>
    </ol>
  </li>
</ul>

<h3 id="density-based-clustering">Density-Based clustering</h3>

<ul>
  <li>The basic idea behind density-based algorithms is that different regions of the vector space can be more or less densely populated.</li>
  <li>Under this view, clusters can take any shape; they are not constrained to convex clusters as in k-means.</li>
</ul>

<p><strong>Directly density-reachable</strong></p>

<ul>
  <li>DBSCAN</li>
</ul>

<hr />

<h2 id="evaluation-of-hard-clustering">Evaluation of hard clustering</h2>

<h3 id="intrinsic-and-extrinsic-evaluation">Intrinsic and extrinsic evaluation</h3>
<ul>
  <li>In <strong>intrinsic</strong> evaluation, a clustering is evaluated based on internal measures such as coherence and separation. <em>Are documents in the same cluster similar? Are clusters well-separated?</em></li>
  <li>In <strong>extrinsic</strong> evaluation, a clustering is evaluated based on data that was not used for the clustering, such as known class labels. <em>cluster purity, Rand index</em></li>
</ul>

<h3 id="rand-index">Rand index</h3>

<p>假設一個集合中有N篇文章
一個集合中有N(N-1)/2個集合對
TP：同一類的文章被分到同一個簇
TN：不同類的文章被分到不同簇
FP：不同類的文章被分到同一個簇
FN：同一類的文章被分到不同簇
Rand Index度量的正確的百分比
RI = （TP+TN）/（TP+FP+FN+TN）</p>

<hr />

<h2 id="topic-models">Topic models</h2>
<ul>
  <li>A topic model is a statistical model for representing the abstract topics that are expressed in a collection of documents.</li>
  <li>Topic models are examples of soft clustering techniques – each document belongs to each cluster (topic) to a certain degree.</li>
</ul>

<h3 id="latent-dirichlet-allocation-lda">Latent Dirichlet Allocation (LDA)</h3>

<p>LDA有兩個原則，</p>
<ol>
  <li>每個 domcuments 是由多個 Topic 組成（each document belongs to each cluster (topic) to a certain degree）</li>
  <li>每個主題會有不同的 terms 來描述，且同樣對詞可以同時出現在不同的主題。</li>
</ol>

<p><img src="http://localhost:4000/blog/img/posts/Topic%20models.png" alt="" /></p>

<p><img src="http://localhost:4000/blog/img/posts/Topic%20models2.png" alt="" /></p>

<hr />

<p><strong>Reference:</strong>
<br />
<a href="https://www.ida.liu.se/~732A92/index.en.shtml">732A92 Texting Mining</a>
<br />
<a href="https://www.ida.liu.se/~732A75/info/courseinfo.en.shtml">732A75 Advanced Data Mining</a>
<br />
<a href="http://cpmarkchang.logdown.com/posts/238079-natural-language-processing-brown-clustering">自然語言處理 – Brown Clustering</a>
<br />
<a href="https://medium.com/@tengyuanchang/直觀理解-lda-latent-dirichlet-allocation-與文件主題模型-ab4f26c27184">直觀理解 LDA (Latent Dirichlet Allocation) 與文件主題模型</a>
<br />
<a href="https://www.twblogs.net/a/5b8c83e12b717718833363ae">聚類評價指標 Rand Index,RI,Recall,Precision,F1</a></p>
</div>
</div>

<div class="likecoin">
  
  <iframe
    src="https://button.like.co/in/embed/shihs_tw/button?referrer=http%3A%2F%2Flocalhost%3A4000%2Fblog%2F2019%2F11%2FText-Mining-Text-clustering-and-topic-modelling.html" height="200" width="560" allowfullscreen="" frameborder="0"
  >
  </iframe>
  
</div>

  
<a name="comments"></a>
<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
var disqus_config = function () {
        // this.page.url = '/blog//#disqus_thread';
        this.page.identifier = '/2019/11/Text-Mining-Text-clustering-and-topic-modelling.html';
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://mcshihs.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>



  <div class="related">
    <h2>Latest Posts</h2>
    <ul class="related-posts">
      
      <li>
        <h3>
          <a href="/blog/2023/09/Python-Class-Object-Instance-%E7%9A%84%E9%97%9C%E4%BF%82.html"> [Python]Class、Object、Instance 的關係 </a>
          <small>Sep 11, 2023</small>
        </h3>
      </li>
      
      <li>
        <h3>
          <a href="/blog/2022/06/MongoDB-%E5%BB%BA%E7%AB%8B-Cloud-MongoDB.html"> [MongoDB]建立 Cloud MongoDB </a>
          <small>Jun 10, 2022</small>
        </h3>
      </li>
      
      <li>
        <h3>
          <a href="/blog/2022/04/Flask-%E5%9F%BA%E6%9C%AC%E5%AF%A6%E5%81%9A.html"> [Python][Flask]Flask 基本實做 </a>
          <small>Apr 6, 2022</small>
        </h3>
      </li>
      
    </ul>
  </div>
</div>

    </div>
    <script id="dsq-count-scr" src="//mcshihs.disqus.com/count.js" async></script>
  </body>
</html>
