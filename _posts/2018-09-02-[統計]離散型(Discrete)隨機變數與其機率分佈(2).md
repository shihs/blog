---
layout: post
comments: true
title: "[統計]離散型(Discrete)隨機變數與其機率分佈(2)"
date: 2018-09-02 11:21
author: "Shihs"
category: [統計]
---

這一系列我是以 
Wackerley, Mendenhall and Scheaffer 的 <br>
Mathematical Statistics with Applications, 7th edition 這本書為主，<br>
有些名詞與定理解釋會再參考其他書籍與網路作為輔助（下方有參考連結）。

這篇關於期望值的介紹在書中的 3.3，但這篇內容有很大部分也來自 [Source](https://www.probabilitycourse.com/chapter3/3_2_2_expectation.php)


***
### 期望值 Expectation ###
**定義 Definition**

* Let \\(X\\) be a discrete random variable with range \\(R_X = \\{ x_1, x_2, x_3,... \\} \\)(finite or countably infinite). The expectation of \\(X\\) is defined as

$$E(X) = \sum_{\substack{x_k \in R_X}}x_kP(X=x)=\sum_{\substack{x_k \in R_X}}x_kP_X(x_k)$$


且期望值 \\(E(X)\\) 會等於平均數 \\(\mu\\)

$$E(X) = \mu$$


說明：

>
There is a discrete random variable with range \\(R_X = \\{ x_1, x_2, x_3,... \\} \\). Suppose that we repeat this experiment a very large number of times \\(N\\), and that the trials are independent. Let \\(N_1\\) be the number of times we observe \\(x_1\\), \\(N_2\\) be the number of times we observe \\(x_2, ....\\), \\(N_k\\) be the number of times we observe \\(x_k\\).

$$
P_X(x_1) \approx\frac{N_1}{N} \\
P_X(x_2) \approx\frac{N_2}{N} \\
\cdots\\
P_X(x_k) \approx\frac{N_k}{N} \\
\cdots
$$

>
從以上式子我們可以得到 \\(N_k = NP_X(x_k)\\)

$$
\begin{align}
\mu & = \frac{N_1x_1 + N_2x_2 + N_3x_3 + ...}{N} \\
& \approx \frac{x_1NP_X(x_1) + x_2NP_X(x_2) + x_3NP_X(x_3) + ...}{N} \\
& = x_1P_X(x_1) + x_2P_X(x_2) + x_3P_X(x_3) + ... \\
& = E(X)
\end{align}
$$

以上就是 \\(E(X) = \mu\\) 的說明。




另外，可能會看到一些不同的寫法表示期望值

$$E(X)=E[X]=EX=\mu=\mu_X$$


這部分內容主要來源為 [Source](https://www.probabilitycourse.com/chapter3/3_2_2_expectation.php)

***
### Law of the unconscious statistician (LOTUS) ###
**THEOREM 3.2**
* Let \\(X\\) be a discrete random variable with probability function \\(P(x)\\) and \\(g(X)\\) be a real-valued function of \\(Y\\). Then the expected value of \\(g(X)\\) is given by

$$E[g(X)] = \sum_{\substack{x \in R_X}}g(x)P(x)$$


**Example:** <br>
[Source](https://www.probabilitycourse.com/chapter3/3_2_3_functions_random_var.php)
>
Let \\(X\\) be a discrete random variable with range \\(R_X = \\{ 0, \frac{\pi}{4}, \frac{\pi}{2}, \frac{3\pi}{4}, \pi... \\} \\), such that \\(P_X(0)=P_X(\frac{\pi}{4})=P_X(\frac{\pi}{2})=P_X(\frac{3\pi}{4})=P_X(\pi)=\frac{1}{5}\\).  Find \\(E[sin(X)]\\).

Solution:

>
根據 LOTUS，
$$
\begin{align}
E[\sin(X)] & = \sum_{\substack{x \in R_X}}\sin(x)P(x) \\
& = \sin(0)P_X(0) +  \sin(\frac{\pi}{4})P_X(\frac{\pi}{4}) + \sin(\frac{\pi}{2})P_X(\frac{\pi}{2}) + \sin(\frac{3\pi}{4})P_X(\frac{3\pi}{4}) + \sin(\pi)P_X(\pi)\\
& = 0 \times \frac{1}{5} + \frac{\sqrt{2}}{2} \times \frac{1}{5} + 1 \times \frac{1}{5} + \frac{\sqrt{2}}{2} \times \frac{1}{5} + 0 \times \frac{1}{5} \\
& = \frac{\sqrt{2} + 1}{2}
\end{align}
$$

***
### 變異數 Variance ###
**定義 Definition**

* If \\(X\\) is a random variable with mean \\(E[X] = \mu\\), the variance of \\(X\\) is defined as 

$$
Var(X) = E[(X - \mu)^2]
$$

* 且根據 LOTUS，這個式子可以再寫成

$$
Var(X) = E[(X - \mu)^2] = \sum_{\substack{x \in R_X}}(X - \mu)^2P(x)
$$

***
### 期望值的運算 ###
**THEOREM 3.3**

* Let X be a discrete random variable with probability function \\(p(x)\\) and \\(c\\) be a constant. Then 

$$
E(c) = c.
$$

**THEOREM 3.4**
* Let X be a discrete random variable with probability function \\(p(x)\\) and \\(g(X)\\) be a function of X, and c be as constant. Then 

$$
E[cg(X)] = cE[g(X)].
$$

**THEOREM 3.5**
* Let X be a discrete random variable with probability function \\(p(x)\\) and \\(g_1(X), g_2(X), ..., g_k(X)\\) be \\(k\\) functions of \\(X\\). Then

$$
E[g_1(X)+g_2(X)+...+g_k(X)] = E[g_1(X)] + E[g_2(X)] + ... + E[g_k(X)]
$$


根據以上定理，可以再產生

**THEOREM 3.6**
* Let X be a discrete random variable with probability function \\(p(x)\\) and mean \\(E(X) = \mu\\). Then 

$$
\begin{align}
V(X) = \sigma^2 & = E[(X - \mu)^2] \\
& = E(X^2) - \mu^2 \\
& = E(X^2) - E^2(X) \\
\end{align}
$$

證明：

>
$$
\begin{align}
\sigma^2 & = E[(X - \mu)^2] & \\
& = E[(X^2 - 2\mu X + \mu^2] \\
& = E(X^2) - E(2\mu X) + E(\mu^2) \\
& = E(X^2) - 2\mu E(X) + \mu^2 \\
& = E(X^2) - 2\mu^2 + \mu^2 \\
& = E(X^2) - \mu^2 \\
& = E(X^2) - E^2(X) \\
\end{align}
$$


***
參考：

* [Introduce To Proability, Statistics and Random Process](https://www.probabilitycourse.com)
* [陳鍾誠的網站](http://ccckmit.wikidot.com/st:main)
* [Allan G. Bluman Elementary Statistics – a step by step approach](https://bmalone.weebly.com/uploads/2/2/3/9/22391186/bluman_statistics_book.pdf)


